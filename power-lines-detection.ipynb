{"cells":[{"cell_type":"code","execution_count":null,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\r\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\r\n","# For example, here's several helpful packages to load\r\n","\r\n","import numpy as np # linear algebra\r\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n","\r\n","# Input data files are available in the read-only \"../input/\" directory\r\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\r\n","\r\n","import os\r\n","'''for dirname, _, filenames in os.walk('/kaggle/input'):\r\n","    for filename in filenames:\r\n","        print(os.path.join(dirname, filename))'''\r\n","\r\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \r\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":["# ****Function for detecting Horizontal and Vertical edges in a image****"],"metadata":{}},{"cell_type":"markdown","source":["### Kernel_1 is for detecting the vertical edges and kernel_2 is for detecting the horizontal edges and this detection makes the image more clear for detecting the power lines"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from scipy.signal import convolve2d\r\n","import matplotlib.pyplot as plt\r\n","\r\n","kernel_1 = np.array([[-1, 0, 1],\r\n","                   [-1, 0, 1],\r\n","                   [-1, 0, 1]])\r\n","kernel_2 = np.array([[-1, -1, -1],\r\n","                   [0, 0, 0],\r\n","                   [1, 1, 1]])\r\n","def edge(im):\r\n","    out1 = convolve2d(im, kernel_1)\r\n","    out2 = convolve2d(im, kernel_2)\r\n","    new=np.sqrt(np.square(out1)+np.square(out2))\r\n","    return new\r\n","\r\n","def make(im):\r\n","    im= cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\r\n","    a=edge(im)\r\n","    a=a[:128,:128]\r\n","    im1=im.reshape(128,128,1)\r\n","    im2=a.reshape(128,128,1)\r\n","    return np.concatenate((im1,im2), axis=2)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Loading the training Dataset****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import cv2 \r\n","import os \r\n","import glob \r\n","img_dir = \"/kaggle/input/recognizance-2/Data/train/Powerline\" # Enter Directory of all images  \r\n","data_path = os.path.join(img_dir,'*.bmp') \r\n","files = glob.glob(data_path) \r\n","train = [] \r\n","train_labels=[]\r\n","images=[]\r\n","for f1 in files: \r\n","    img = cv2.imread(f1) \r\n","    images.append(img)\r\n","    train.append(make(img))\r\n","    train_labels.append(1)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["plt.imshow(images[0])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["img_dir = \"/kaggle/input/recognizance-2/Data/train/No_powerline\" # Enter Directory of all images  \r\n","data_path = os.path.join(img_dir,'*.bmp') \r\n","files = glob.glob(data_path) \r\n","for f1 in files: \r\n","    img = cv2.imread(f1)\r\n","    images.append(img)\r\n","    train.append(make(img))\r\n","    train_labels.append(0)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["plt.imshow(images[len(images)-1])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Shuffling the training images and labels****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import random\r\n","temp=list(zip(train,train_labels))\r\n","for i in range(100):\r\n","    random.shuffle(temp)\r\n","train,train_labels=zip(*temp)\r\n","train=np.array(train)\r\n","train_labels=np.array(train_labels)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["train[0].shape"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["train=np.array(train)\r\n","train_labels=np.array(train_labels)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["train.shape"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Importing the necessary Libraries****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import seaborn as sns\r\n","%matplotlib inline\r\n","\r\n","np.random.seed(2)\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.metrics import confusion_matrix\r\n","import itertools\r\n","\r\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\r\n","from keras.optimizers import RMSprop\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","\r\n","sns.set(style='white', context='notebook', palette='deep')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Initializing our Model****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = Sequential()\r\n","model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \r\n","                 activation ='relu', input_shape = (128,128,2)))\r\n","model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(MaxPool2D(pool_size=(2,2)))\r\n","model.add(Dropout(0.25))\r\n","\r\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(MaxPool2D(pool_size=(2,2)))\r\n","model.add(Dropout(0.25))\r\n","\r\n","\r\n","\r\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\r\n","\r\n","\r\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \r\n","                 activation ='relu'))\r\n","model.add(MaxPool2D(pool_size=(2,2)))\r\n","model.add(Dropout(0.25))\r\n","\r\n","model.add(Flatten())\r\n","model.add(Dense(512, activation = \"relu\"))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(1, activation = \"sigmoid\"))"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Model Prototype****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model.summary()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["optimizer =  RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\r\n","model.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\r\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \r\n","                                            patience=3, \r\n","                                            verbose=1, \r\n","                                            factor=0.5, \r\n","                                            min_lr=0.00001)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\r\n","batch_size = 100"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["X_train, X_val, Y_train, Y_val = train_test_split(train, train_labels, test_size = 0.1, random_state= 2)\r\n","X_train=X_train/255.0\r\n","X_val=X_val/255.0"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["X_train=train/255.0\r\n","Y_train=train_labels"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Training our model****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["history = model.fit( X_train,Y_train, batch_size=batch_size,\r\n","                              epochs = 30, \r\n","                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\r\n","                               )"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["del train"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["del train_labels"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Loading the test Dataset****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["img_dir = \"/kaggle/input/recognizance-2/Data/test\" # Enter Directory of all images  \r\n","data_path = os.path.join(img_dir,'*.bmp') \r\n","files = glob.glob(data_path) \r\n","test_images = []\r\n","for f1 in files: \r\n","    img = cv2.imread(f1) \r\n","    test_images.append(make(img)) "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["del X_train"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_images=np.array(test_images)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_images=test_images/255.0"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_images.shape"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# ****Predicting the test images****"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["test_labels=model.predict(test_images)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["labels=[]\r\n","for i in test_labels:\r\n","    if(i>0.5):\r\n","        labels.append(\"YES\")\r\n","    else:\r\n","        labels.append(\"NO\")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_names=[]\r\n","for f1 in files:  \r\n","    test_names.append(f1)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["for i in range(0,len(test_images)):\r\n","    test_names[i]=test_names[i][39:]\r\n","test_names[0] "],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["file=pd.DataFrame(test_names,columns=['image file name'])\r\n","file['Powerline']=labels\r\n","file"],"outputs":[],"metadata":{"trusted":true}}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}